{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddad2ac-660c-4b1f-9f11-121951f4820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import optuna\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import json\n",
    "#from dask.distributed import Client, progress, wait\n",
    "#from IPython.display import display, HTML\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..','..','..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.models.lr_ssd.snn__logn_gtv import SNN__LOGN_GTV\n",
    "from src.models.horpca.horpca_torch import HoRPCA_Singleton\n",
    "#from dask.distributed import as_completed\n",
    "from tqdm import tqdm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import math\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "from src.synthetic_data.generate_lr_data import generate_low_rank_data\n",
    "from src.synthetic_data.generate_anomaly import generate_spatio_temporal_anomaly\n",
    "from src.multilinear_ops.t2m import t2m\n",
    "\n",
    "\n",
    "\n",
    "def get_data(data_variables):\n",
    "    seed = data_variables['seed']\n",
    "    lr_variables = data_variables['lowrank']\n",
    "    graph_variables = data_variables['graph']\n",
    "    an_variables = data_variables['anomaly']\n",
    "    noise = data_variables.get('noise', None)\n",
    "\n",
    "    X_gt = generate_low_rank_data(**lr_variables, seed=seed)\n",
    "    std = lr_variables.get('std', None)\n",
    "    if std is not None:\n",
    "        X_gt = std*X_gt/ (X_gt.std())\n",
    "\n",
    "    gtype = graph_variables['type']\n",
    "    if gtype == 'grid':\n",
    "        G = nx.grid_2d_graph(graph_variables['n'], graph_variables['m'], \n",
    "                             periodic=graph_variables.get('periodic', False))\n",
    "    elif gtype == 'Gnm':\n",
    "        G = nx.gnm_random_graph(graph_variables['n'], graph_variables['m'],\n",
    "                                seed=graph_variables['seed'],\n",
    "                                directed=graph_variables['directed'])\n",
    "    elif gtype == 'random_regular':\n",
    "        G = nx.random_regular_graph(graph_variables['d'], graph_variables['n'],\n",
    "                                    seed=graph_variables['seed'])\n",
    "    else:\n",
    "        raise ValueError('Invalid graph type')\n",
    "    \n",
    "    Gt = nx.grid_graph((X_gt.shape[an_variables['time_m']-1], ), periodic=False)\n",
    "    \n",
    "    S_gt, labels = generate_spatio_temporal_anomaly(X_gt.shape, G, \n",
    "                                                    **an_variables,\n",
    "                                                    seed=seed)\n",
    "    \n",
    "    if noise is not None:\n",
    "        power_X_db = 10*np.log(np.linalg.norm(X_gt))\n",
    "        power_N_db = power_X_db - noise['SNR']\n",
    "        power_N = 10**(power_N_db/10)\n",
    "        N = np.random.randn(*X_gt.shape)\n",
    "        N = N/np.linalg.norm(N)*np.sqrt(power_N)\n",
    "        Y = X_gt + S_gt + N\n",
    "    else:\n",
    "        Y = X_gt + S_gt\n",
    "    return {'Y': Y, 'X_gt': X_gt, 'S_gt': S_gt, 'G':G, 'labels': labels, 'Gt': Gt}\n",
    "\n",
    "\n",
    "def calculate_metrics(results, data):\n",
    "    model = results['model']\n",
    "    model_eps = results['model_eps']\n",
    "    X_gt = data['X_gt']\n",
    "    S_gt = data['S_gt']\n",
    "    labels = data['labels']\n",
    "    device = model.device\n",
    "    fpr, tpr, thresholds = roc_curve(labels.ravel(),\n",
    "                                    torch.abs(model.S).ravel().cpu().numpy())\n",
    "    precision, recall, thresholds = precision_recall_curve(labels.ravel(),\n",
    "                                        torch.abs(model.S).ravel().cpu().numpy())\n",
    "    auc_prc_score = auc(recall, precision)\n",
    "    auc_roc_score = auc(fpr, tpr)\n",
    "\n",
    "    metrics = {'BIC': model.bic[-1],\n",
    "               'AUC-ROC':auc_roc_score,\n",
    "               'AUC-PRC':auc_prc_score,\n",
    "               'S_diff': torch.norm(model.S-model_eps.S).cpu().item(),\n",
    "               'L_diff': torch.norm(model.X-model_eps.X).cpu().item(),\n",
    "               'L_nuc_1': torch.linalg.matrix_norm(t2m(model.X, 1), 'nuc').cpu().item(),\n",
    "               'L_nuc_2': torch.linalg.matrix_norm(t2m(model.X, 2), 'nuc').cpu().item(),\n",
    "               'L_nuc_3': torch.linalg.matrix_norm(t2m(model.X, 3), 'nuc').cpu().item(),\n",
    "               'S_nuc_1': torch.linalg.matrix_norm(t2m(model.S, 1), 'nuc').cpu().item(),\n",
    "               'S_nuc_2': torch.linalg.matrix_norm(t2m(model.S, 2), 'nuc').cpu().item(),\n",
    "               'S_nuc_3': torch.linalg.matrix_norm(t2m(model.S, 3), 'nuc').cpu().item(),\n",
    "               'L_nuc_1_eps': torch.linalg.matrix_norm(t2m(model_eps.X, 1), 'nuc').cpu().item(),\n",
    "               'L_nuc_2_eps': torch.linalg.matrix_norm(t2m(model_eps.X, 2), 'nuc').cpu().item(),\n",
    "               'L_nuc_3_eps': torch.linalg.matrix_norm(t2m(model_eps.X, 3), 'nuc').cpu().item(),\n",
    "               'S_nuc_1_eps': torch.linalg.matrix_norm(t2m(model_eps.S, 1), 'nuc').cpu().item(),\n",
    "               'S_nuc_2_eps': torch.linalg.matrix_norm(t2m(model_eps.S, 2), 'nuc').cpu().item(),\n",
    "               'S_nuc_3_eps': torch.linalg.matrix_norm(t2m(model_eps.S, 3), 'nuc').cpu().item(),\n",
    "               'L1':  torch.sum(torch.abs(model.X)).cpu().item(),\n",
    "               'L1_eps':  torch.sum(torch.abs(model_eps.X)).cpu().item(),\n",
    "               'S1': torch.sum(torch.abs(model.S)).cpu().item(),\n",
    "               'S1_eps': torch.sum(torch.abs(model_eps.S)).cpu().item(),\n",
    "               'nonzero_S': (torch.sum(model.S != 0)/torch.prod(torch.tensor(model.S.shape))).cpu().item(),\n",
    "               'nonzero_L': (torch.sum(model.X != 0)/torch.prod(torch.tensor(model.S.shape))).cpu().item(),\n",
    "               'ranks_S1': torch.linalg.matrix_rank(t2m(model.S, 1)).cpu().item(),\n",
    "               'ranks_S2': torch.linalg.matrix_rank(t2m(model.S, 2)).cpu().item(),\n",
    "               'ranks_S3': torch.linalg.matrix_rank(t2m(model.S, 3)).cpu().item(),\n",
    "               'ranks_L1': torch.linalg.matrix_rank(t2m(model.X, 1)).cpu().item(),\n",
    "               'ranks_l2': torch.linalg.matrix_rank(t2m(model.S, 2)).cpu().item(),\n",
    "               'ranks_l3': torch.linalg.matrix_rank(t2m(model.S, 3)).cpu().item(),\n",
    "               'S_fro': torch.norm(model.S).cpu().item(),\n",
    "               'L_fro': torch.norm(model.X).cpu().item(),\n",
    "               'L_fro_eps': torch.norm(model_eps.X).cpu().item(),\n",
    "               'S_fro_eps': torch.norm(model_eps.S).cpu().item(),\n",
    "               'S_err': (torch.norm(torch.tensor(S_gt, device=device)-model.S).cpu().numpy()/np.linalg.norm(S_gt)).item(),\n",
    "               'L_err': (torch.norm(torch.tensor(X_gt, device=device)-model.X).cpu().numpy()/np.linalg.norm(X_gt)).item()\n",
    "                }\n",
    "    metrics['tol']=metrics['S_err']+metrics['L_err'] # tol = S_err + L_err\n",
    "    metrics['diff'] = metrics['S_diff']+metrics['L_diff'] # diff = S_diff + L_diff\n",
    "    return metrics\n",
    "\n",
    "\n",
    "data_variables = {\n",
    "  'lowrank':{\n",
    "    'dim': [40, 24, 7, 20],\n",
    "    'ranks': [8,8,5,5]\n",
    "  },\n",
    "  'graph':{\n",
    "    'type': \"grid\",\n",
    "    'n': 8,\n",
    "    'm': 5,\n",
    "    'periodic': False,\n",
    "    'seed': 0,\n",
    "  },\n",
    "  'anomaly':{\n",
    "    'amplitude': 0.25,\n",
    "    'num_anomalies': 300,\n",
    "    'duration': 4, # 4, 8, 12, 16, 20, 24 \n",
    "    'radius': 1,\n",
    "    'window_type': 'boxcar', #'cosine', 'boxcar'\n",
    "    'distribution': 'uniform',\n",
    "    'local_dist': 'constant',\n",
    "    'time_m': 2,\n",
    "    'local_m': 1,\n",
    "    'anomaly_spread': 'isotropic',\n",
    "  },\n",
    "   'noise':{\n",
    "    'type': 'AWGN',\n",
    "    'SNR': 10,\n",
    "    },\n",
    "  'seed':1,\n",
    "}\n",
    "\n",
    "data = get_data(data_variables)\n",
    "## Control Variables\n",
    "Y = data['Y']\n",
    "lr_stss_select = {}\n",
    "lr_stss_select['lr_modes'] = [1,2,3,4]\n",
    "lr_stss_select['graph_modes'] = [1]\n",
    "lr_stss_select['grouping'] = 'neighbor'\n",
    "lr_stss_select['weighing'] = 'uniform'\n",
    "lr_stss_select['r_hop'] = 0\n",
    "lr_stss_select['device'] = 'cuda:1'\n",
    "lr_stss_select['dtype'] = torch.float64\n",
    "lr_stss_select['verbose'] = 0\n",
    "lr_stss_select['gtvr_config'] = [{'graph':'spatial',\n",
    "                       'mode':[1],\n",
    "                       'p': 1,\n",
    "                       'variation_type': 'GTMV',\n",
    "                       'normalization': 'symmetric'},\n",
    "                       {'graph':'temporal',\n",
    "                        'mode':[2],\n",
    "                        'variation_type': 'GTV',\n",
    "                        'p':1,}]\n",
    "lr_sts_select = {}\n",
    "lr_sts_select['lr_modes'] = [1,2,3,4]\n",
    "lr_sts_select['graph_modes'] = [1]\n",
    "lr_sts_select['grouping'] = 'neighbor'\n",
    "lr_sts_select['weighing'] = 'uniform'\n",
    "lr_sts_select['r_hop'] = 0\n",
    "lr_sts_select['device'] = 'cuda:1'\n",
    "lr_sts_select['dtype'] = torch.float64\n",
    "lr_sts_select['verbose'] = 0\n",
    "lr_sts_select['gtvr_config'] = [{'graph':'temporal',\n",
    "                        'mode':[2],\n",
    "                        'variation_type': 'GTV',\n",
    "                        'p':1,}]\n",
    "\n",
    "lr_sss_select = {}\n",
    "lr_sss_select['lr_modes'] = [1,2,3,4]\n",
    "lr_sss_select['graph_modes'] = [1]\n",
    "lr_sss_select['grouping'] = 'neighbor'\n",
    "lr_sss_select['weighing'] = 'uniform'\n",
    "lr_sss_select['r_hop'] = 0\n",
    "lr_sss_select['device'] = 'cuda:1'\n",
    "lr_sss_select['dtype'] = torch.float64\n",
    "lr_sss_select['verbose'] = 0\n",
    "lr_sss_select['gtvr_config'] = [{'graph':'spatial',\n",
    "                       'mode':[1],\n",
    "                       'p': 1,\n",
    "                       'variation_type': 'GTMV',\n",
    "                       'normalization': 'symmetric'},\n",
    "                       ]\n",
    "\n",
    "horpca_select = {}\n",
    "horpca_select['lr_modes'] = [1,2,3,4]\n",
    "horpca_select['graph_modes'] = [1]\n",
    "horpca_select['grouping'] = 'neighbor'\n",
    "horpca_select['weighing'] = 'uniform'\n",
    "horpca_select['r_hop'] = 0\n",
    "horpca_select['device'] = 'cuda:1'\n",
    "horpca_select['dtype'] = torch.float64\n",
    "horpca_select['verbose'] = 0\n",
    "horpca_select['gtvr_config'] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def search_hp(data_variables, model_name, n_trials):\n",
    "    \n",
    "    data = get_data(data_variables)\n",
    "    G = data['G']\n",
    "    S_gt = data['S_gt']\n",
    "    an_m = data['labels']\n",
    "    Y = data['Y']\n",
    "    X = data['X_gt']\n",
    "    A = nx.adjacency_matrix(G)\n",
    "\n",
    "    study = optuna.create_study(directions=['maximize', 'maximize'])\n",
    "    def objective(trial):\n",
    "        psi = trial.suggest_float('psi', 0, 1)\n",
    "        lda_1 = 1-psi\n",
    "        var2 = {}\n",
    "        var2['psis'] = [psi]*4\n",
    "        var2['lda'] = 1-psi\n",
    "        var2['max_iter'] = 100\n",
    "        var2['rho'] = 4*np.abs(Y).sum()/Y.size\n",
    "        var2['err_tol'] = 1e-6\n",
    "        var2['rho_update'] = 1\n",
    "        var2['rho_update_thr'] = 100\n",
    "        if model_name == 'lr_stss':\n",
    "            lda_l = trial.suggest_float('lda_l', 1e-8, 10, log=True)\n",
    "            lda_t = trial.suggest_float('lda_t', 1e-8, 10, log=True)\n",
    "            var2['lda_gtvs'] = [lda_l, lda_t]\n",
    "            model = SNN__LOGN_GTV(Y, G, **lr_stss_select)\n",
    "        elif model_name == 'lr_sts':\n",
    "            lda_t = trial.suggest_float('lda_t', 1e-8, 10, log=True)\n",
    "            lda_l = 0\n",
    "            var2['lda_gtvs'] = [lda_t]\n",
    "            model = SNN__LOGN_GTV(Y, G, **lr_sts_select)\n",
    "        elif model_name == 'lr_sss':\n",
    "            lda_t = 0\n",
    "            lda_l = trial.suggest_float('lda_l', 1e-8, 10, log=True)\n",
    "            var2['lda_gtvs'] = [lda_l]\n",
    "            model = SNN__LOGN_GTV(Y, G, **lr_sss_select)\n",
    "        elif model_name == 'horpca':\n",
    "            lda_t = 0\n",
    "            lda_l = 0\n",
    "            var2['lda_gtvs'] = []\n",
    "            model = SNN__LOGN_GTV(Y, G, **horpca_select)\n",
    "        \n",
    "        trial.set_user_attr('psi', psi)\n",
    "        trial.set_user_attr('lda_1', lda_1)\n",
    "        trial.set_user_attr('lda_t', lda_t)\n",
    "        trial.set_user_attr('lda_l', lda_l)\n",
    "        trial.set_user_attr('number_of_anomalies', noa)\n",
    "        trial.set_user_attr('anomaly_cardinality', an_m.sum())\n",
    "        trial.set_user_attr('duration', duration)\n",
    "\n",
    "        \n",
    "        L, S,r,s,o = model(**var2)\n",
    "        L = L.cpu().numpy()\n",
    "        S = S.cpu().numpy()\n",
    "        S_loc = t2m(S, m = 1)\n",
    "        \n",
    "        r_A = np.eye(S_loc.shape[0])+np.linalg.matrix_power(A.toarray(),radius)\n",
    "        likelihood = np.zeros(S_loc.shape)\n",
    "\n",
    "        for s in range(S_loc.shape[0]):\n",
    "            mask = r_A[np.where(r_A[s,]!=0),:].astype(bool)\n",
    "            nbd = S_loc[mask[:,0,:].ravel(),:]\n",
    "            # Append neighbors from additional columns in mask\n",
    "            for m in range(1, mask.shape[1]):\n",
    "                nbd = np.vstack((nbd,S_loc[mask[:,m,:].ravel(),:] ))\n",
    "                \n",
    "            W = np.zeros(nbd.shape)\n",
    "            # Iterate through the columns in steps of block_size\n",
    "            for i1 in range(0, 3360, 140):\n",
    "                # Slice the matrix to get the block (columns from i to i + block_size)\n",
    "                if i1==0:\n",
    "                    block = nbd[:, i1:i1 + 140]\n",
    "                    for loc in range(nbd.shape[0]):\n",
    "                        W[loc, i1:i1+140] = norm.pdf(np.linalg.norm(block[loc,:] - S_loc[s,i1:i1+140]),0,30)\n",
    "                elif i1==3220:\n",
    "                    block = nbd[:, i1-140:i1 + 140]\n",
    "                    for loc in range(nbd.shape[0]):\n",
    "                        W[loc, i1:i1+140] = norm.pdf(np.linalg.norm(block[loc,:] - S_loc[s,i1-140:i1+140]),0,30)\n",
    "                else:\n",
    "                    block = nbd[:, i1-140:i1 + 280]\n",
    "                    for loc in range(nbd.shape[0]):\n",
    "                        W[loc, i1:i1+140] = norm.pdf(np.linalg.norm(block[loc,:] - S_loc[s,i1-140:i1+280]),0,30)\n",
    "                        \n",
    "            mean = np.sum(W * nbd) / np.sum(W)\n",
    "            sd = np.sqrt(np.sum(W * (nbd - mean)**2) / np.sum(W))\n",
    "            likelihood[s,] = np.log(sd) + (0.5*np.power(((S_loc[s,] - mean)/sd),2))\n",
    "        \n",
    "        truth = an_m.ravel().reshape(-1,1)\n",
    "        sig = math.floor(100*(1-(sum(truth)/(len(S.ravel())))))/100\n",
    "        det = np.zeros(S_loc.shape)\n",
    "        q = np.quantile(likelihood,sig)\n",
    "        det[likelihood > q] = 1\n",
    "        detected_events = det.ravel().reshape(-1,1)\n",
    "        truth = an_m.ravel().reshape(-1,1)\n",
    "        roc_auc = roc_auc_score(an_m.ravel(),likelihood.ravel())\n",
    "        F_score = f1_score(truth, det.reshape(-1,1), average='binary')\n",
    "        auc = roc_auc_score(an_m.ravel(),np.abs(S).ravel())\n",
    "        \n",
    "        trial.set_user_attr('F_score', F_score)\n",
    "        trial.set_user_attr('roc_auc', roc_auc)\n",
    "        trial.set_user_attr('auc', auc)\n",
    "        import optuna\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import optuna\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import json\n",
    "#from dask.distributed import Client, progress, wait\n",
    "#from IPython.display import display, HTML\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..','..','..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.models.lr_ssd.snn__logn_gtv import SNN__LOGN_GTV\n",
    "from src.models.horpca.horpca_torch import HoRPCA_Singleton\n",
    "#from dask.distributed import as_completed\n",
    "from tqdm import tqdm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import math\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "from src.synthetic_data.generate_lr_data import generate_low_rank_data\n",
    "from src.synthetic_data.generate_anomaly import generate_spatio_temporal_anomaly\n",
    "from src.multilinear_ops.t2m import t2m\n",
    "\n",
    "\n",
    "\n",
    "def get_data(data_variables):\n",
    "    seed = data_variables['seed']\n",
    "    lr_variables = data_variables['lowrank']\n",
    "    graph_variables = data_variables['graph']\n",
    "    an_variables = data_variables['anomaly']\n",
    "    noise = data_variables.get('noise', None)\n",
    "\n",
    "    X_gt = generate_low_rank_data(**lr_variables, seed=seed)\n",
    "    std = lr_variables.get('std', None)\n",
    "    if std is not None:\n",
    "        X_gt = std*X_gt/ (X_gt.std())\n",
    "\n",
    "    gtype = graph_variables['type']\n",
    "    if gtype == 'grid':\n",
    "        G = nx.grid_2d_graph(graph_variables['n'], graph_variables['m'], \n",
    "                             periodic=graph_variables.get('periodic', False))\n",
    "    elif gtype == 'Gnm':\n",
    "        G = nx.gnm_random_graph(graph_variables['n'], graph_variables['m'],\n",
    "                                seed=graph_variables['seed'],\n",
    "                                directed=graph_variables['directed'])\n",
    "    elif gtype == 'random_regular':\n",
    "        G = nx.random_regular_graph(graph_variables['d'], graph_variables['n'],\n",
    "                                    seed=graph_variables['seed'])\n",
    "    else:\n",
    "        raise ValueError('Invalid graph type')\n",
    "    \n",
    "    Gt = nx.grid_graph((X_gt.shape[an_variables['time_m']-1], ), periodic=False)\n",
    "    \n",
    "    S_gt, labels = generate_spatio_temporal_anomaly(X_gt.shape, G, \n",
    "                                                    **an_variables,\n",
    "                                                    seed=seed)\n",
    "    \n",
    "    if noise is not None:\n",
    "        power_X_db = 10*np.log(np.linalg.norm(X_gt))\n",
    "        power_N_db = power_X_db - noise['SNR']\n",
    "        power_N = 10**(power_N_db/10)\n",
    "        N = np.random.randn(*X_gt.shape)\n",
    "        N = N/np.linalg.norm(N)*np.sqrt(power_N)\n",
    "        Y = X_gt + S_gt + N\n",
    "    else:\n",
    "        Y = X_gt + S_gt\n",
    "    return {'Y': Y, 'X_gt': X_gt, 'S_gt': S_gt, 'G':G, 'labels': labels, 'Gt': Gt}\n",
    "\n",
    "\n",
    "def calculate_metrics(results, data):\n",
    "    model = results['model']\n",
    "    model_eps = results['model_eps']\n",
    "    X_gt = data['X_gt']\n",
    "    S_gt = data['S_gt']\n",
    "    labels = data['labels']\n",
    "    device = model.device\n",
    "    fpr, tpr, thresholds = roc_curve(labels.ravel(),\n",
    "                                    torch.abs(model.S).ravel().cpu().numpy())\n",
    "    precision, recall, thresholds = precision_recall_curve(labels.ravel(),\n",
    "                                        torch.abs(model.S).ravel().cpu().numpy())\n",
    "    auc_prc_score = auc(recall, precision)\n",
    "    auc_roc_score = auc(fpr, tpr)\n",
    "\n",
    "    metrics = {'BIC': model.bic[-1],\n",
    "               'AUC-ROC':auc_roc_score,\n",
    "               'AUC-PRC':auc_prc_score,\n",
    "               'S_diff': torch.norm(model.S-model_eps.S).cpu().item(),\n",
    "               'L_diff': torch.norm(model.X-model_eps.X).cpu().item(),\n",
    "               'L_nuc_1': torch.linalg.matrix_norm(t2m(model.X, 1), 'nuc').cpu().item(),\n",
    "               'L_nuc_2': torch.linalg.matrix_norm(t2m(model.X, 2), 'nuc').cpu().item(),\n",
    "               'L_nuc_3': torch.linalg.matrix_norm(t2m(model.X, 3), 'nuc').cpu().item(),\n",
    "               'S_nuc_1': torch.linalg.matrix_norm(t2m(model.S, 1), 'nuc').cpu().item(),\n",
    "               'S_nuc_2': torch.linalg.matrix_norm(t2m(model.S, 2), 'nuc').cpu().item(),\n",
    "               'S_nuc_3': torch.linalg.matrix_norm(t2m(model.S, 3), 'nuc').cpu().item(),\n",
    "               'L_nuc_1_eps': torch.linalg.matrix_norm(t2m(model_eps.X, 1), 'nuc').cpu().item(),\n",
    "               'L_nuc_2_eps': torch.linalg.matrix_norm(t2m(model_eps.X, 2), 'nuc').cpu().item(),\n",
    "               'L_nuc_3_eps': torch.linalg.matrix_norm(t2m(model_eps.X, 3), 'nuc').cpu().item(),\n",
    "               'S_nuc_1_eps': torch.linalg.matrix_norm(t2m(model_eps.S, 1), 'nuc').cpu().item(),\n",
    "               'S_nuc_2_eps': torch.linalg.matrix_norm(t2m(model_eps.S, 2), 'nuc').cpu().item(),\n",
    "               'S_nuc_3_eps': torch.linalg.matrix_norm(t2m(model_eps.S, 3), 'nuc').cpu().item(),\n",
    "               'L1':  torch.sum(torch.abs(model.X)).cpu().item(),\n",
    "               'L1_eps':  torch.sum(torch.abs(model_eps.X)).cpu().item(),\n",
    "               'S1': torch.sum(torch.abs(model.S)).cpu().item(),\n",
    "               'S1_eps': torch.sum(torch.abs(model_eps.S)).cpu().item(),\n",
    "               'nonzero_S': (torch.sum(model.S != 0)/torch.prod(torch.tensor(model.S.shape))).cpu().item(),\n",
    "               'nonzero_L': (torch.sum(model.X != 0)/torch.prod(torch.tensor(model.S.shape))).cpu().item(),\n",
    "               'ranks_S1': torch.linalg.matrix_rank(t2m(model.S, 1)).cpu().item(),\n",
    "               'ranks_S2': torch.linalg.matrix_rank(t2m(model.S, 2)).cpu().item(),\n",
    "               'ranks_S3': torch.linalg.matrix_rank(t2m(model.S, 3)).cpu().item(),\n",
    "               'ranks_L1': torch.linalg.matrix_rank(t2m(model.X, 1)).cpu().item(),\n",
    "               'ranks_l2': torch.linalg.matrix_rank(t2m(model.S, 2)).cpu().item(),\n",
    "               'ranks_l3': torch.linalg.matrix_rank(t2m(model.S, 3)).cpu().item(),\n",
    "               'S_fro': torch.norm(model.S).cpu().item(),\n",
    "               'L_fro': torch.norm(model.X).cpu().item(),\n",
    "               'L_fro_eps': torch.norm(model_eps.X).cpu().item(),\n",
    "               'S_fro_eps': torch.norm(model_eps.S).cpu().item(),\n",
    "               'S_err': (torch.norm(torch.tensor(S_gt, device=device)-model.S).cpu().numpy()/np.linalg.norm(S_gt)).item(),\n",
    "               'L_err': (torch.norm(torch.tensor(X_gt, device=device)-model.X).cpu().numpy()/np.linalg.norm(X_gt)).item()\n",
    "                }\n",
    "    metrics['tol']=metrics['S_err']+metrics['L_err'] # tol = S_err + L_err\n",
    "    metrics['diff'] = metrics['S_diff']+metrics['L_diff'] # diff = S_diff + L_diff\n",
    "    return metrics\n",
    "\n",
    "\n",
    "data_variables = {\n",
    "  'lowrank':{\n",
    "    'dim': [40, 24, 7, 20],\n",
    "    'ranks': [8,8,5,5]\n",
    "  },\n",
    "  'graph':{\n",
    "    'type': \"grid\",\n",
    "    'n': 8,\n",
    "    'm': 5,\n",
    "    'periodic': False,\n",
    "    'seed': 0,\n",
    "  },\n",
    "  'anomaly':{\n",
    "    'amplitude': 0.25,\n",
    "    'num_anomalies': 300,\n",
    "    'duration': 4, # 4, 8, 12, 16, 20, 24 \n",
    "    'radius': 1,\n",
    "    'window_type': 'boxcar', #'cosine', 'boxcar'\n",
    "    'distribution': 'uniform',\n",
    "    'local_dist': 'constant',\n",
    "    'time_m': 2,\n",
    "    'local_m': 1,\n",
    "    'anomaly_spread': 'isotropic',\n",
    "  },\n",
    "   'noise':{\n",
    "    'type': 'AWGN',\n",
    "    'SNR': 10,\n",
    "    },\n",
    "  'seed':1,\n",
    "}\n",
    "\n",
    "data = get_data(data_variables)\n",
    "## Control Variables\n",
    "Y = data['Y']\n",
    "lr_stss_select = {}\n",
    "lr_stss_select['lr_modes'] = [1,2,3,4]\n",
    "lr_stss_select['graph_modes'] = [1]\n",
    "lr_stss_select['grouping'] = 'neighbor'\n",
    "lr_stss_select['weighing'] = 'uniform'\n",
    "lr_stss_select['r_hop'] = 0\n",
    "lr_stss_select['device'] = 'cuda:1'\n",
    "lr_stss_select['dtype'] = torch.float64\n",
    "lr_stss_select['verbose'] = 0\n",
    "lr_stss_select['gtvr_config'] = [{'graph':'spatial',\n",
    "                       'mode':[1],\n",
    "                       'p': 1,\n",
    "                       'variation_type': 'GTMV',\n",
    "                       'normalization': 'symmetric'},\n",
    "                       {'graph':'temporal',\n",
    "                        'mode':[2],\n",
    "                        'variation_type': 'GTV',\n",
    "                        'p':1,}]\n",
    "lr_sts_select = {}\n",
    "lr_sts_select['lr_modes'] = [1,2,3,4]\n",
    "lr_sts_select['graph_modes'] = [1]\n",
    "lr_sts_select['grouping'] = 'neighbor'\n",
    "lr_sts_select['weighing'] = 'uniform'\n",
    "lr_sts_select['r_hop'] = 0\n",
    "lr_sts_select['device'] = 'cuda:1'\n",
    "lr_sts_select['dtype'] = torch.float64\n",
    "lr_sts_select['verbose'] = 0\n",
    "lr_sts_select['gtvr_config'] = [{'graph':'temporal',\n",
    "                        'mode':[2],\n",
    "                        'variation_type': 'GTV',\n",
    "                        'p':1,}]\n",
    "\n",
    "lr_sss_select = {}\n",
    "lr_sss_select['lr_modes'] = [1,2,3,4]\n",
    "lr_sss_select['graph_modes'] = [1]\n",
    "lr_sss_select['grouping'] = 'neighbor'\n",
    "lr_sss_select['weighing'] = 'uniform'\n",
    "lr_sss_select['r_hop'] = 0\n",
    "lr_sss_select['device'] = 'cuda:1'\n",
    "lr_sss_select['dtype'] = torch.float64\n",
    "lr_sss_select['verbose'] = 0\n",
    "lr_sss_select['gtvr_config'] = [{'graph':'spatial',\n",
    "                       'mode':[1],\n",
    "                       'p': 1,\n",
    "                       'variation_type': 'GTMV',\n",
    "                       'normalization': 'symmetric'},\n",
    "                       ]\n",
    "\n",
    "horpca_select = {}\n",
    "horpca_select['lr_modes'] = [1,2,3,4]\n",
    "horpca_select['graph_modes'] = [1]\n",
    "horpca_select['grouping'] = 'neighbor'\n",
    "horpca_select['weighing'] = 'uniform'\n",
    "horpca_select['r_hop'] = 0\n",
    "horpca_select['device'] = 'cuda:1'\n",
    "horpca_select['dtype'] = torch.float64\n",
    "horpca_select['verbose'] = 0\n",
    "horpca_select['gtvr_config'] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def search_hp(data_variables, model_name, n_trials):\n",
    "    \n",
    "    data = get_data(data_variables)\n",
    "    G = data['G']\n",
    "    S_gt = data['S_gt']\n",
    "    an_m = data['labels']\n",
    "    Y = data['Y']\n",
    "    X = data['X_gt']\n",
    "    A = nx.adjacency_matrix(G)\n",
    "\n",
    "    study = optuna.create_study(directions=['maximize', 'maximize'])\n",
    "    def objective(trial):\n",
    "        psi = trial.suggest_float('psi', 0, 1)\n",
    "        lda_1 = 1-psi\n",
    "        var2 = {}\n",
    "        var2['psis'] = [psi]*4\n",
    "        var2['lda'] = 1-psi\n",
    "        var2['max_iter'] = 100\n",
    "        var2['rho'] = 4*np.abs(Y).sum()/Y.size\n",
    "        var2['err_tol'] = 1e-6\n",
    "        var2['rho_update'] = 1\n",
    "        var2['rho_update_thr'] = 100\n",
    "        if model_name == 'lr_stss':\n",
    "            lda_l = trial.suggest_float('lda_l', 1e-8, 10, log=True)\n",
    "            lda_t = trial.suggest_float('lda_t', 1e-8, 10, log=True)\n",
    "            var2['lda_gtvs'] = [lda_l, lda_t]\n",
    "            model = SNN__LOGN_GTV(Y, G, **lr_stss_select)\n",
    "        elif model_name == 'lr_sts':\n",
    "            lda_t = trial.suggest_float('lda_t', 1e-8, 10, log=True)\n",
    "            lda_l = 0\n",
    "            var2['lda_gtvs'] = [lda_t]\n",
    "            model = SNN__LOGN_GTV(Y, G, **lr_sts_select)\n",
    "        elif model_name == 'lr_sss':\n",
    "            lda_t = 0\n",
    "            lda_l = trial.suggest_float('lda_l', 1e-8, 10, log=True)\n",
    "            var2['lda_gtvs'] = [lda_l]\n",
    "            model = SNN__LOGN_GTV(Y, G, **lr_sss_select)\n",
    "        elif model_name == 'horpca':\n",
    "            lda_t = 0\n",
    "            lda_l = 0\n",
    "            var2['lda_gtvs'] = []\n",
    "            model = SNN__LOGN_GTV(Y, G, **horpca_select)\n",
    "        \n",
    "        trial.set_user_attr('psi', psi)\n",
    "        trial.set_user_attr('lda_1', lda_1)\n",
    "        trial.set_user_attr('lda_t', lda_t)\n",
    "        trial.set_user_attr('lda_l', lda_l)\n",
    "        trial.set_user_attr('number_of_anomalies', noa)\n",
    "        trial.set_user_attr('anomaly_cardinality', an_m.sum())\n",
    "        trial.set_user_attr('duration', duration)\n",
    "\n",
    "        \n",
    "        L, S,r,s,obj = model(**var2)\n",
    "        L = L.cpu().numpy()\n",
    "        S = S.cpu().numpy()\n",
    "        S_loc = t2m(S, m = 1)\n",
    "        \n",
    "        r_A = np.eye(S_loc.shape[0])+np.linalg.matrix_power(A.toarray(),radius)\n",
    "        likelihood = np.zeros(S_loc.shape)\n",
    "\n",
    "        for s in range(S_loc.shape[0]):\n",
    "            mask = r_A[np.where(r_A[s,]!=0),:].astype(bool)\n",
    "            nbd = S_loc[mask[:,0,:].ravel(),:]\n",
    "            # Append neighbors from additional columns in mask\n",
    "            for m in range(1, mask.shape[1]):\n",
    "                nbd = np.vstack((nbd,S_loc[mask[:,m,:].ravel(),:] ))\n",
    "                \n",
    "            W = np.zeros(nbd.shape)\n",
    "            # Iterate through the columns in steps of block_size\n",
    "            for i1 in range(0, 3360, 140):\n",
    "                # Slice the matrix to get the block (columns from i to i + block_size)\n",
    "                if i1==0:\n",
    "                    block = nbd[:, i1:i1 + 140]\n",
    "                    for loc in range(nbd.shape[0]):\n",
    "                        W[loc, i1:i1+140] = norm.pdf(np.linalg.norm(block[loc,:] - S_loc[s,i1:i1+140]),0,30)\n",
    "                elif i1==3220:\n",
    "                    block = nbd[:, i1-140:i1 + 140]\n",
    "                    for loc in range(nbd.shape[0]):\n",
    "                        W[loc, i1:i1+140] = norm.pdf(np.linalg.norm(block[loc,:] - S_loc[s,i1-140:i1+140]),0,30)\n",
    "                else:\n",
    "                    block = nbd[:, i1-140:i1 + 280]\n",
    "                    for loc in range(nbd.shape[0]):\n",
    "                        W[loc, i1:i1+140] = norm.pdf(np.linalg.norm(block[loc,:] - S_loc[s,i1-140:i1+280]),0,30)\n",
    "                        \n",
    "            mean = np.sum(W * nbd) / np.sum(W)\n",
    "            sd = np.sqrt(np.sum(W * (nbd - mean)**2) / np.sum(W))\n",
    "            likelihood[s,] = np.log(sd) + (0.5*np.power(((S_loc[s,] - mean)/sd),2))\n",
    "        \n",
    "        truth = an_m.ravel().reshape(-1,1)\n",
    "        sig = math.floor(100*(1-(sum(truth)/(len(S.ravel())))))/100\n",
    "        det = np.zeros(S_loc.shape)\n",
    "        q = np.quantile(likelihood,sig)\n",
    "        det[likelihood > q] = 1\n",
    "        detected_events = det.ravel().reshape(-1,1)\n",
    "        truth = an_m.ravel().reshape(-1,1)\n",
    "        roc_auc = roc_auc_score(an_m.ravel(),likelihood.ravel())\n",
    "        F_score = f1_score(truth, det.reshape(-1,1), average='binary')\n",
    "        auc = roc_auc_score(an_m.ravel(),np.abs(S).ravel())\n",
    "        \n",
    "        trial.set_user_attr('F_score', F_score)\n",
    "        trial.set_user_attr('roc_auc', roc_auc)\n",
    "        trial.set_user_attr('auc', auc)\n",
    "        trial.set_user_attr('primal_residual', r)\n",
    "        trial.set_user_attr('dual_residual', s)\n",
    "        trial.set_user_attr('objective', obj)\n",
    "        \n",
    "        return roc_auc, F_score\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study\n",
    "\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249aa1b6-1754-4a30-9720-ca346a778bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 15:41:19,502] A new study created in memory with name: no-name-ba93a038-ac90-4fa8-b59d-723998df1287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model:  lr_stss\n",
      "Running for model:  lr_stss\n",
      "Running for model:  lr_stss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ffs24/home/mondalra/Anomaly_Detection/src/proximal_ops/prox_overlapping_grouped_l21.py:404: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1742922447420/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  G_ind = torch.sparse_csr_tensor(A_r.indptr, A_r.indices, A_r.data, device=device, dtype=dtype)\n",
      "/tmp/local/56371698/ipykernel_2753873/796056952.py:680: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sig = math.floor(100*(1-(sum(truth)/(len(S.ravel())))))/100\n",
      "[I 2025-05-15 15:41:23,270] Trial 0 finished with values: [0.6159867710122718, 0.0730635838150289] and parameters: {'psi': 0.029770520712728343, 'lda_l': 2.7451256864040595e-05, 'lda_t': 0.01123799427900405}.\n",
      "/tmp/local/56371698/ipykernel_2753873/796056952.py:680: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sig = math.floor(100*(1-(sum(truth)/(len(S.ravel())))))/100\n",
      "[I 2025-05-15 15:41:26,342] Trial 1 finished with values: [0.6151689569911717, 0.03930635838150289] and parameters: {'psi': 0.5642281654695377, 'lda_l': 0.0003490550259797749, 'lda_t': 0.013345362844862622}.\n",
      "/tmp/local/56371698/ipykernel_2753873/796056952.py:680: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sig = math.floor(100*(1-(sum(truth)/(len(S.ravel())))))/100\n",
      "[I 2025-05-15 15:41:29,505] Trial 2 finished with values: [0.7078764111102835, 0.08323699421965318] and parameters: {'psi': 0.9247503250930952, 'lda_l': 0.000692300385833172, 'lda_t': 3.971588268848161e-05}.\n",
      "/tmp/local/56371698/ipykernel_2753873/796056952.py:680: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sig = math.floor(100*(1-(sum(truth)/(len(S.ravel())))))/100\n",
      "[I 2025-05-15 15:41:32,403] Trial 3 finished with values: [0.6889010994375723, 0.06936416184971098] and parameters: {'psi': 0.9362955177120827, 'lda_l': 1.260812495875038e-07, 'lda_t': 1.0097960984856946e-08}.\n",
      "/tmp/local/56371698/ipykernel_2753873/796056952.py:680: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sig = math.floor(100*(1-(sum(truth)/(len(S.ravel())))))/100\n",
      "[I 2025-05-15 15:41:35,459] Trial 4 finished with values: [0.48535286382676, 0.012023121387283236] and parameters: {'psi': 0.47779377196681116, 'lda_l': 0.00034994707234795063, 'lda_t': 0.2921862195911382}.\n"
     ]
    }
   ],
   "source": [
    "    rep = 0\n",
    "    models = ['lr_stss'] #['lr_stss', 'lr_sts', 'lr_sss', 'horpca']\n",
    "    duration = 4\n",
    "    n_trials = 5 #1000\n",
    "    n_iteration = 1\n",
    "    radius = 1\n",
    "    noa = 100\n",
    "    res = []\n",
    "    for m, model in enumerate(models):\n",
    "            print(\"Running for model: \", model)\n",
    "            print(\"Running for model: \", model)\n",
    "            print(\"Running for model: \", model)\n",
    "            seed = rep+1\n",
    "            data_variables['anomaly']['radius'] = radius\n",
    "            data_variables['anomaly']['duration'] = duration\n",
    "            data_variables['anomaly']['num_anomalies'] = noa\n",
    "            data_variables['seed'] = seed\n",
    "            study = search_hp(data_variables, model, n_trials)\n",
    "            best_trial = max(study.best_trials, key=lambda x: x.values[1])\n",
    "            lda_1_opt = best_trial.user_attrs['lda_1']\n",
    "            lda_t_opt = best_trial.user_attrs['lda_t']\n",
    "            lda_l_opt = best_trial.user_attrs['lda_l']\n",
    "            psi_opt = best_trial.params['psi']\n",
    "            F_score_opt = best_trial.user_attrs['F_score']\n",
    "            roc_auc_opt = best_trial.user_attrs['roc_auc']\n",
    "            primal_res = best_trial.user_attrs['primal_residual']\n",
    "            dual_res = best_trial.user_attrs['dual_residual']\n",
    "            objective = best_trial.user_attrs['objective']\n",
    "            res.append({'seed': seed, 'primal_res': primal_res, 'dual_res': dual_res, 'objective': objective })\n",
    "            # df = pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da2d3d5-d33c-4d01-b05b-b5333fd8a0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'seed': 1,\n",
       "  'primal_res': [tensor(35.3477, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(25.0190, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(12.2715, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(9.4439, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(12.9164, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(13.0563, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(10.2090, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(6.8917, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(5.2317, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(5.0937, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(5.0207, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(4.5673, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(3.9799, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(3.5532, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(3.3243, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(3.1434, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(2.9043, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(2.6160, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(2.3501, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(2.1615, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(2.0491, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.9739, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.9025, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.8251, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.7453, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.6691, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.5960, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.5228, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.4484, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.3746, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.3050, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.2421, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.1858, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.1349, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.0875, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(1.0421, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.9977, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.9541, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.9114, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.8699, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.8304, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.7938, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.7605, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.7303, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.7029, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.6775, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.6537, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.6304, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.6075, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.5851, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.5632, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.5423, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.5226, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.5043, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.4873, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.4714, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.4563, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.4419, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.4279, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.4144, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.4016, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3894, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3781, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3674, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3574, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3480, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3390, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3304, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3220, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3138, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.3059, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2982, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2909, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2838, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2770, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2705, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2644, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2585, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2529, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2475, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2423, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2373, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2324, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2276, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2231, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2187, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2144, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2103, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2062, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.2023, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1984, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1947, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1912, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1879, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1846, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1814, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1782, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1751, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1720, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(0.1689, device='cuda:1', dtype=torch.float64)],\n",
       "  'dual_res': 39,\n",
       "  'objective': [tensor(22.5759, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(87.2748, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(164.1303, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(240.8893, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(291.7526, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(325.8393, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(360.5926, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(387.4982, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(405.8679, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(420.9484, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(437.6524, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(457.6779, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(479.8167, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(501.1913, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(518.6339, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(529.9463, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(534.4694, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(533.3528, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(528.6225, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(522.7233, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(517.5944, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(514.4290, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(513.6539, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(514.9796, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(517.5547, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4328, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(522.9000, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(524.5439, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(525.2530, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(525.1552, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(524.5045, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(523.5814, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(522.6138, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.7661, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.1233, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.7082, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4930, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4368, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4826, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5917, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.7326, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.8851, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.0371, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.1762, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.3008, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.4047, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.4771, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.5046, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.4861, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.4246, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.3188, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.1902, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(521.0465, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.8989, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.7546, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6321, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5390, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4784, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4464, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4426, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4607, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4926, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5313, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5702, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6072, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6374, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6567, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6661, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6659, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6575, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6401, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.6179, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5903, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5636, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5391, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5168, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4984, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4867, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4802, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4796, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4834, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.4901, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5009, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5133, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5241, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5355, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5480, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5594, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5692, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5768, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5818, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5839, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5837, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5836, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5840, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5851, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5862, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5883, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5923, device='cuda:1', dtype=torch.float64),\n",
       "   tensor(520.5964, device='cuda:1', dtype=torch.float64)]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd44a5e-71cb-4421-b0b8-337d0c1d3d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
